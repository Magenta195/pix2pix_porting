{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz -O facades.tar.gz\n",
    "!tar -zxvf facades.tar.gz -C ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"학습 데이터셋 A와 B의 개수:\", len(next(os.walk('./facades/train/'))[2]))\n",
    "print(\"평가 데이터셋 A와 B의 개수:\", len(next(os.walk('./facades/val/'))[2]))\n",
    "print(\"테스트 데이터셋 A와 B의 개수:\", len(next(os.walk('./facades/test/'))[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한 쌍의 이미지 출력(왼쪽은 정답 이미지, 오른쪽은 조건 이미지)\n",
    "image = Image.open('./facades/train/1.jpg')\n",
    "print(\"이미지 크기:\", image.size)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_train(image_file):\n",
    "  input_image, real_image = load(image_file)\n",
    "  input_image, real_image = random_jitter(input_image, real_image)\n",
    "  input_image, real_image = normalize(input_image, real_image)\n",
    "\n",
    "  return input_image, real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNetDown(in_channels, out_channels, normalize=True, dropout=0.0) :\n",
    "    initializer = tf.random_normal_initializer(0.0, 0.02)\n",
    "\n",
    "    layers = [ tf.keras.layers.Conv2D(filters = out_channels, kernel_size = 4, strides=2, padding='same',\n",
    "                             kernel_initializer=initializer, use_bias=False) ]\n",
    "    if normalize :\n",
    "        layers.append( tf.keras.layers.BatchNormalization(axis=[0,1]) )\n",
    "    if dropout :\n",
    "        layers.append( tf.keras.layers.Dropout(dropout) )\n",
    "    layers.append(tf.keras.layers.LeakyReLU(0.2))\n",
    "    model = tf.keras.Sequential( layers )\n",
    "    return model\n",
    "\n",
    "def UNetUp(in_channels, out_channels, dropout=0.0) :\n",
    "    initializer = tf.random_normal_initializer(0.0, 0.02)\n",
    "    layers = [ tf.keras.layers.Conv2DTranspose(filters = out_channels, kernel_size = 4, strides=2,\n",
    "                                    padding='same',\n",
    "                                    kernel_initializer=initializer,\n",
    "                                    use_bias=False) ]\n",
    "    layers.append( tf.keras.layers.BatchNormalization(axis=[0,1]) )\n",
    "    layers.append( tf.keras.layers.ReLU() )\n",
    "    if dropout :\n",
    "        layers.append( tf.keras.layers.Dropout(dropout) )\n",
    "    model = tf.keras.Sequential(layers)\n",
    "    return model\n",
    "\n",
    "def GeneratorUNet(in_channels = 3, out_channels = 3):\n",
    "    inputs = tf.keras.layers.Input(shape=[256, 256, in_channels])\n",
    "    downs = [\n",
    "        UNetDown(3, 64, normalize=False),\n",
    "        UNetDown(64, 128),\n",
    "        UNetDown(128, 256),\n",
    "        UNetDown(256, 512, dropout = 0.5),\n",
    "        UNetDown(512, 512, dropout = 0.5),\n",
    "        UNetDown(512, 512, dropout = 0.5),\n",
    "        UNetDown(512, 512, dropout = 0.5),\n",
    "        UNetDown(512, 512, normalize = False, dropout = 0.5),\n",
    "    ]\n",
    "    ups = [\n",
    "        UNetUp(512, 512, dropout=0.5),\n",
    "        UNetUp(1024, 512, dropout=0.5),\n",
    "        UNetUp(1024, 512, dropout=0.5),  \n",
    "        UNetUp(1024, 512, dropout=0.5),  \n",
    "        UNetUp(1024, 256),  \n",
    "        UNetUp(512, 128),  \n",
    "        UNetUp(256, 64)  \n",
    "    ]\n",
    "\n",
    "    final_init = tf.random_normal_initializer(0.0, 0.02)\n",
    "    final = tf.keras.layers.Conv2DTranspose(out_channels, kennel_size= 4, strides=2,\n",
    "                                         padding='same',\n",
    "                                         kernel_initializer=final_init,\n",
    "                                         activation='tanh')  # (batch_size, 256, 256, 3)\n",
    "\n",
    "\n",
    "    ### forward   \n",
    "    x = inputs\n",
    "    skip_connections = list()\n",
    "    for i in range(len(downs)) :\n",
    "        x = downs[i](x)\n",
    "        if i < len(downs)-1 :\n",
    "            skip_connections.append(x)\n",
    "\n",
    "    skip_connections.reverse()\n",
    "\n",
    "    for i in range(len(ups)) :\n",
    "        x = ups[i](x)\n",
    "        x = tf.keras.layers.Concatenate()([x, skip_connections[i]])\n",
    "    x = final(x)\n",
    "\n",
    "    return tf.keras.Model(inputs = inputs, outputs = x)\n",
    "\n",
    "def Discriminator(in_channels = 3) :\n",
    "\n",
    "    def discriminator_block(in_channels, out_channels, normalization=True):\n",
    "        initializer = tf.random_normal_initializer(0., 0.02)\n",
    "        layers = [ tf.keras.layers.Conv2D(filters = out_channels, kernel_size = 4, strides=2, padding='same',\n",
    "                                    kernel_initializer=initializer, use_bias=False) ]\n",
    "        if normalization :\n",
    "            layers.append( tf.keras.layers.BatchNormalization(axis=[0,1]) )\n",
    "        layers.append(tf.keras.layers.LeakyReLU(0.2))\n",
    "        return layers\n",
    "    \n",
    "    initializer = tf.random_normal_initializer(0., 0.02)\n",
    "    layers = list()\n",
    "    layers.extend( discriminator_block(in_channels*2, 64, normalization = False))\n",
    "    layers.extend( discriminator_block(64, 128) )\n",
    "    layers.extend( discriminator_block(128, 256) )\n",
    "    layers.extend( discriminator_block(256, 512) )\n",
    "\n",
    "    layers.append(tf.keras.layers.ZeroPadding2D(padding = ((1, 0), (1, 0))))\n",
    "    layers.append(tf.keras.layers.Conv2D(filters = 1, kernel_size = 4, strides=1, padding='same',\n",
    "                                    kernel_initializer=initializer, use_bias=False))\n",
    "    model = tf.keras.Sequential(layers)\n",
    "\n",
    "    ### forward\n",
    "    img_A = tf.keras.layers.Input(shape=[256, 256, 3], name='input')\n",
    "    img_B = tf.keras.layers.Input(shape=[256, 256, 3], name='target')\n",
    "    x = tf.keras.layers.Concatenate()([img_A, img_B])\n",
    "    x = model(x)\n",
    "\n",
    "    return tf.keras.Model(inputs = [img_A, img_B], outputs = x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
